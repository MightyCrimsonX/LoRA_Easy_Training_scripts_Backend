{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lightning AI SDXL LoRA Trainer\n\nEste cuaderno prepara un entorno dentro de Lightning AI (ruta raíz ``/teamspace/studios/this_studio``)\ny ejecuta el entrenador de LoRA para Stable Diffusion XL incluido en este fork.\n\nLos pasos principales son:\n\n1. Crear/usar un entorno gestionado por [uv](https://github.com/astral-sh/uv).\n2. Instalar las dependencias necesarias.\n3. Definir la configuración de entrenamiento (epochs, repeats, tasas de aprendizaje, etc.).\n4. Ejecutar el entrenamiento calculando automáticamente los *steps* mediante la fórmula requerida.",
        "\n5. Seleccionar optimizadores personalizados (AdamW8bit, Prodigy, DAdapt*, Lion, etc.) y schedulers (`cosine`, `rex`, `cosine_with_restarts`, entre otros) incluidos en este fork.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from pathlib import Path\nimport os\nimport subprocess\n\nLIGHTNING_ROOT = Path(\"/teamspace/studios/this_studio\")\nUV_BIN = Path.home() / \".local\" / \"bin\" / \"uv\"\n\nif not UV_BIN.exists():\n    print(\"Instalando uv…\")\n    subprocess.run(\n        [\"/bin/bash\", \"-lc\", \"curl -LsSf https://astral.sh/uv/install.sh | sh\"],\n        check=True,\n    )\nelse:\n    print(\"uv ya está instalado\")\n\nos.environ[\"PATH\"] = f\"{UV_BIN.parent}:{os.environ['PATH']}\"\nos.environ.setdefault(\"UV_PROJECT_ENVIRONMENT\", str(LIGHTNING_ROOT / \".venv\"))\nprint(\"Entorno de uv:\", os.environ[\"UV_PROJECT_ENVIRONMENT\"])"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "required_packages = [\n",
        "    \"bitsandbytes\",\n",
        "    \"prodigyopt\",\n",
        "    \"lion-pytorch\",\n",
        "    \"dadaptation\",\n",
        "    \"pytorch-optimizer==3.1.2\",\n",
        "    \"torch>=2.1\",\n",
        "    \"torchvision\",\n",
        "    \"accelerate>=0.23\",\n",
        "    \"diffusers[torch]>=0.24\",\n",
        "    \"transformers>=4.35\",\n",
        "    \"peft>=0.7\",\n",
        "    \"safetensors\",\n",
        "]\n",
        "\n",
        "print(\"Instalando dependencias con uv…\")\n",
        "subprocess.run([\"uv\", \"pip\", \"install\", \"--upgrade\", *required_packages], check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\nfrom lightning_ai.sdxl_lora_trainer import TrainingConfig\n\nbase_config = TrainingConfig(\n    dataset_metadata=Path(\"datasets/mi_dataset/metadata.jsonl\"),\n    images_root=Path(\"datasets/mi_dataset/images\"),\n    output_dir=Path(\"outputs/sdxl_lora_demo\"),\n    num_epochs=2,\n    batch_size=1,\n    gradient_accumulation=1,\n    num_repeats=2,\n    resolution=1024,\n    network_rank=64,\n    network_alpha=128,\n    unet_lr=1e-4,\n    text_encoder_lr=5e-6,\n    optimizer_type=\"adamw\",\n    weight_decay=1e-2,\n    optimizer_beta1=0.9,\n    optimizer_beta2=0.999,\n    optimizer_eps=1e-8,\n    optimizer_momentum=0.9,\n    scheduler_type=\"cosine\",\n    lr_warmup_steps=None,\n    scheduler_first_cycle_steps=None,\n    scheduler_cycle_multiplier=1.0,\n    scheduler_gamma=1.0,\n    scheduler_min_lr=1e-6,\n    scheduler_d=0.9,\n    scheduler_power=1.0,\n    train_text_encoders=True,\n    mixed_precision=\"fp16\",\n)\n\nconfig = base_config.normalised_paths()\nprint(\"Configuración resuelta:\")\nfor key, value in config.__dict__.items():\n    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import json\nfrom lightning_ai.sdxl_lora_trainer import calculate_total_steps\n\nnum_images = 0\nwith config.dataset_metadata.open(\"r\", encoding=\"utf-8\") as handle:\n    for line in handle:\n        if line.strip():\n            num_images += 1\n\nsteps = calculate_total_steps(\n    num_images=num_images,\n    num_repeats=config.num_repeats,\n    num_epochs=config.num_epochs,\n    batch_size=config.batch_size,\n)\nprint(json.dumps(\n    {\n        \"num_images\": num_images,\n        \"num_repeats\": config.num_repeats,\n        \"num_epochs\": config.num_epochs,\n        \"batch_size\": config.batch_size,\n        \"calculated_steps\": steps,\n    },\n    indent=2,\n))"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "from lightning_ai.sdxl_lora_trainer import train\n\nprint(\"Iniciando entrenamiento…\")\ntrain(config)"
    }
  ]
}