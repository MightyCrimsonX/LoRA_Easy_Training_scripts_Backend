{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning AI SDXL LoRA Trainer\n",
    "\n",
    "Este cuaderno prepara un entorno dentro de Lightning AI (ruta raíz ``/teamspace/studios/this_studio``)\n",
    "y ejecuta el entrenador de LoRA para Stable Diffusion XL incluido en este fork.\n",
    "\n",
    "Los pasos principales son:\n",
    "\n",
    "1. Crear/usar un entorno gestionado por [uv](https://github.com/astral-sh/uv).\n",
    "2. Organizar el dataset en la carpeta `dataset/`, colocando cada imagen junto a un archivo `.txt` con el mismo nombre\n",
    "   que contenga sus tags/prompts. Puedes definir *activation tags* globales y habilitar el mezclado de tags desde la\n",
    "   configuración.\n",
    "3. Instalar las dependencias necesarias.\n",
    "4. Definir la configuración de entrenamiento (epochs, repeats, tasas de aprendizaje, tags, modelo base, etc.).\n",
    "5. Ejecutar el entrenamiento calculando automáticamente los *steps* mediante la fórmula requerida.\n",
    "6. Seleccionar optimizadores personalizados (AdamW8bit, Prodigy, DAdapt*, Lion, etc.) y schedulers (`cosine`, `rex`,\n",
    "   `cosine_with_restarts`, entre otros) incluidos en este fork.\n",
    "\n",
    "7. Activa o desactiva los valores recomendados de cada optimizador con `use_optimizer_recommended_args` si quieres aplicar los presets sugeridos (Adafactor, AdamW8bit, Prodigy y CAME) sin tocar manualmente `optimizer_kwargs`.\n",
    "\n",
    "8. Define el nombre final del archivo LoRA con `lora_name` o la bandera `--lora-name` para controlar el `.safetensors` generado.\n",
    "\n",
    "Modelos base disponibles (`base_model` o `--base-model`):\n",
    "\n",
    "- `Pony Diffusion V6 XL` → `PonyDiffusion/Pony-Diffusion-V6-XL`\n",
    "- `Animagine XL V3` → `cagliostrolab/animagine-xl-3.0`\n",
    "- `animagine_4.0_zero` → `cagliostrolab/animagine-xl-4.0-zero`\n",
    "- `Illustrious_0.1` → `stabilityai/illustrious-xl-0.1`\n",
    "- `Illustrious_2.0` → `stabilityai/illustrious-xl-2.0`\n",
    "- `NoobAI-XL0.75` → `NoobAI/NoobAI-XL0.75`\n",
    "- `Stable Diffusion XL 1.0 base` → `stabilityai/stable-diffusion-xl-base-1.0`\n",
    "- `NoobAIXL0_75vpred` → `NoobAI/NoobAIXL0.75-vPred`\n",
    "- `RouWei_v080vpred` → `RouWei/RouWei-v0.80-vPred`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "LIGHTNING_ROOT = Path(\"/teamspace/studios/this_studio\")\n",
    "UV_BIN = Path.home() / \".local\" / \"bin\" / \"uv\"\n",
    "\n",
    "if not UV_BIN.exists():\n",
    "    print(\"Instalando uv…\")\n",
    "    subprocess.run(\n",
    "        [\"/bin/bash\", \"-lc\", \"curl -LsSf https://astral.sh/uv/install.sh | sh\"],\n",
    "        check=True,\n",
    "    )\n",
    "else:\n",
    "    print(\"uv ya está instalado\")\n",
    "\n",
    "os.environ[\"PATH\"] = f\"{UV_BIN.parent}:{os.environ['PATH']}\"\n",
    "os.environ.setdefault(\"UV_PROJECT_ENVIRONMENT\", str(LIGHTNING_ROOT / \".venv\"))\n",
    "print(\"Entorno de uv:\", os.environ[\"UV_PROJECT_ENVIRONMENT\"])\n",
    "\n",
    "repo_root = Path.cwd().resolve()\n",
    "if not (repo_root / \"lightning_ai\").exists():\n",
    "    candidate = repo_root / \"LoRA_Easy_Training_scripts_Backend\"\n",
    "    if candidate.exists():\n",
    "        repo_root = candidate.resolve()\n",
    "if not (repo_root / \"lightning_ai\").exists():\n",
    "    raise FileNotFoundError(\"No se encontró la carpeta 'lightning_ai' junto al notebook.\")\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "print(\"Repositorio detectado en:\", repo_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "required_packages = [\n",
    "    \"numpy<2\",\n",
    "    \"bitsandbytes\",\n",
    "    \"prodigyopt\",\n",
    "    \"lion-pytorch\",\n",
    "    \"dadaptation\",\n",
    "    \"pytorch-optimizer==3.1.2\",\n",
    "    \"torch>=2.1\",\n",
    "    \"torchvision\",\n",
    "    \"accelerate>=0.23\",\n",
    "    \"diffusers[torch]>=0.24\",\n",
    "    \"transformers>=4.35\",\n",
    "    \"peft>=0.7\",\n",
    "    \"safetensors\",\n",
    "]\n",
    "\n",
    "print(\"Instalando dependencias con uv…\")\n",
    "subprocess.run([\"uv\", \"pip\", \"install\", \"--upgrade\", *required_packages], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from lightning_ai.sdxl_lora_trainer import BASE_MODEL_CHOICES, TrainingConfig\n",
    "\n",
    "base_config = TrainingConfig(\n",
    "    dataset_dir=Path(\"dataset\"),  # carpeta con imágenes y .txt emparejados\n",
    "    output_dir=Path(\"outputs/sdxl_lora_demo\"),\n",
    "    num_epochs=2,\n",
    "    batch_size=1,\n",
    "    gradient_accumulation=1,\n",
    "    num_repeats=2,\n",
    "    resolution=1024,\n",
    "    network_rank=64,\n",
    "    network_alpha=128,\n",
    "    base_model=\"Stable Diffusion XL 1.0 base\",\n",
    "    unet_lr=1e-4,\n",
    "    text_encoder_lr=5e-6,\n",
    "    optimizer_type=\"adamw\",\n",
    "    weight_decay=1e-2,\n",
    "    optimizer_beta1=0.9,\n",
    "    optimizer_beta2=0.999,\n",
    "    optimizer_eps=1e-8,\n",
    "    optimizer_momentum=0.9,\n",
    "    scheduler_type=\"cosine\",\n",
    "    lr_warmup_steps=None,\n",
    "    scheduler_first_cycle_steps=None,\n",
    "    scheduler_cycle_multiplier=1.0,\n",
    "    scheduler_gamma=1.0,\n",
    "    scheduler_min_lr=1e-6,\n",
    "    scheduler_d=0.9,\n",
    "    scheduler_power=1.0,\n",
    "    train_text_encoders=True,\n",
    "    mixed_precision=\"fp16\",\n",
    "    shuffle_tags=True,\n",
    "    activation_tags=(\"mi_lora\",),\n",
    "    use_optimizer_recommended_args=True,\n",
    "    lora_name=\"mi_lora_personalizado\",  # la extensión .safetensors se añade si falta\n",
    ")\n",
    "\n",
    "print(\"Modelos base disponibles:\")\n",
    "for name in BASE_MODEL_CHOICES:\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "config = base_config.normalised_paths()\n",
    "print(\"Configuración resuelta:\")\n",
    "for key, value in config.__dict__.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from lightning_ai.sdxl_lora_trainer import FolderCaptionDataset, calculate_total_steps\n",
    "\n",
    "preview_dataset = FolderCaptionDataset(\n",
    "    dataset_dir=config.dataset_dir,\n",
    "    resolution=config.resolution,\n",
    "    activation_tags=config.activation_tags,\n",
    "    shuffle_tags=config.shuffle_tags,\n",
    ")\n",
    "\n",
    "num_images = len(preview_dataset)\n",
    "steps = calculate_total_steps(\n",
    "    num_images=num_images,\n",
    "    num_repeats=config.num_repeats,\n",
    "    num_epochs=config.num_epochs,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "print(json.dumps(\n",
    "    {\n",
    "        \"num_images\": num_images,\n",
    "        \"num_repeats\": config.num_repeats,\n",
    "        \"num_epochs\": config.num_epochs,\n",
    "        \"batch_size\": config.batch_size,\n",
    "        \"calculated_steps\": steps,\n",
    "    },\n",
    "    indent=2,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from lightning_ai.sdxl_lora_trainer import train\n\nprint(\"Iniciando entrenamiento…\")\ntrain(config)"
  }
 ]
}