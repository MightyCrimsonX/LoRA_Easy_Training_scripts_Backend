{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning AI SDXL LoRA Trainer\n",
    "\n",
    "Este cuaderno prepara un entorno dentro de Lightning AI (ruta ra\u00edz ``/teamspace/studios/this_studio``)\n",
    "y ejecuta el entrenador de LoRA para Stable Diffusion XL incluido en este fork.\n",
    "\n",
    "Los pasos principales son:\n",
    "\n",
    "1. Crear/usar un entorno gestionado por [uv](https://github.com/astral-sh/uv).\n",
    "2. Organizar el dataset en la carpeta `dataset/`, colocando cada imagen junto a un archivo `.txt` con el mismo nombre\n",
    "   que contenga sus tags/prompts. Puedes definir *activation tags* globales y habilitar el mezclado de tags desde la\n",
    "   configuraci\u00f3n.\n",
    "3. Instalar las dependencias necesarias.\n",
    "4. Definir la configuraci\u00f3n de entrenamiento (epochs, repeats, tasas de aprendizaje, tags, etc.).\n",
    "5. Ejecutar el entrenamiento calculando autom\u00e1ticamente los *steps* mediante la f\u00f3rmula requerida.\n",
    "6. Seleccionar optimizadores personalizados (AdamW8bit, Prodigy, DAdapt*, Lion, etc.) y schedulers (`cosine`, `rex`,\n",
    "   `cosine_with_restarts`, entre otros) incluidos en este fork.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from pathlib import Path\nimport os\nimport subprocess\n\nLIGHTNING_ROOT = Path(\"/teamspace/studios/this_studio\")\nUV_BIN = Path.home() / \".local\" / \"bin\" / \"uv\"\n\nif not UV_BIN.exists():\n    print(\"Instalando uv\u2026\")\n    subprocess.run(\n        [\"/bin/bash\", \"-lc\", \"curl -LsSf https://astral.sh/uv/install.sh | sh\"],\n        check=True,\n    )\nelse:\n    print(\"uv ya est\u00e1 instalado\")\n\nos.environ[\"PATH\"] = f\"{UV_BIN.parent}:{os.environ['PATH']}\"\nos.environ.setdefault(\"UV_PROJECT_ENVIRONMENT\", str(LIGHTNING_ROOT / \".venv\"))\nprint(\"Entorno de uv:\", os.environ[\"UV_PROJECT_ENVIRONMENT\"])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "required_packages = [\n",
    "    \"bitsandbytes\",\n",
    "    \"prodigyopt\",\n",
    "    \"lion-pytorch\",\n",
    "    \"dadaptation\",\n",
    "    \"pytorch-optimizer==3.1.2\",\n",
    "    \"torch>=2.1\",\n",
    "    \"torchvision\",\n",
    "    \"accelerate>=0.23\",\n",
    "    \"diffusers[torch]>=0.24\",\n",
    "    \"transformers>=4.35\",\n",
    "    \"peft>=0.7\",\n",
    "    \"safetensors\",\n",
    "]\n",
    "\n",
    "print(\"Instalando dependencias con uv\u2026\")\n",
    "subprocess.run([\"uv\", \"pip\", \"install\", \"--upgrade\", *required_packages], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from lightning_ai.sdxl_lora_trainer import TrainingConfig\n",
    "\n",
    "base_config = TrainingConfig(\n",
    "    dataset_dir=Path(\"dataset\"),  # carpeta con im\u00e1genes y .txt emparejados\n",
    "    output_dir=Path(\"outputs/sdxl_lora_demo\"),\n",
    "    num_epochs=2,\n",
    "    batch_size=1,\n",
    "    gradient_accumulation=1,\n",
    "    num_repeats=2,\n",
    "    resolution=1024,\n",
    "    network_rank=64,\n",
    "    network_alpha=128,\n",
    "    unet_lr=1e-4,\n",
    "    text_encoder_lr=5e-6,\n",
    "    optimizer_type=\"adamw\",\n",
    "    weight_decay=1e-2,\n",
    "    optimizer_beta1=0.9,\n",
    "    optimizer_beta2=0.999,\n",
    "    optimizer_eps=1e-8,\n",
    "    optimizer_momentum=0.9,\n",
    "    scheduler_type=\"cosine\",\n",
    "    lr_warmup_steps=None,\n",
    "    scheduler_first_cycle_steps=None,\n",
    "    scheduler_cycle_multiplier=1.0,\n",
    "    scheduler_gamma=1.0,\n",
    "    scheduler_min_lr=1e-6,\n",
    "    scheduler_d=0.9,\n",
    "    scheduler_power=1.0,\n",
    "    train_text_encoders=True,\n",
    "    mixed_precision=\"fp16\",\n",
    "    shuffle_tags=True,\n",
    "    activation_tags=(\"mi_lora\",),\n",
    ")\n",
    "\n",
    "config = base_config.normalised_paths()\n",
    "print(\"Configuraci\u00f3n resuelta:\")\n",
    "for key, value in config.__dict__.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from lightning_ai.sdxl_lora_trainer import FolderCaptionDataset, calculate_total_steps\n",
    "\n",
    "preview_dataset = FolderCaptionDataset(\n",
    "    dataset_dir=config.dataset_dir,\n",
    "    resolution=config.resolution,\n",
    "    activation_tags=config.activation_tags,\n",
    "    shuffle_tags=config.shuffle_tags,\n",
    ")\n",
    "\n",
    "num_images = len(preview_dataset)\n",
    "steps = calculate_total_steps(\n",
    "    num_images=num_images,\n",
    "    num_repeats=config.num_repeats,\n",
    "    num_epochs=config.num_epochs,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "print(json.dumps(\n",
    "    {\n",
    "        \"num_images\": num_images,\n",
    "        \"num_repeats\": config.num_repeats,\n",
    "        \"num_epochs\": config.num_epochs,\n",
    "        \"batch_size\": config.batch_size,\n",
    "        \"calculated_steps\": steps,\n",
    "    },\n",
    "    indent=2,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from lightning_ai.sdxl_lora_trainer import train\n\nprint(\"Iniciando entrenamiento\u2026\")\ntrain(config)"
  }
 ]
}