{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning AI SDXL LoRA Trainer (kohya)\n\n",
    "Este cuaderno prepara un entorno dentro de Lightning AI (ruta ra\u00edz ``/teamspace/studios/this_studio``)\n",
    "y utiliza la integraci\u00f3n reciente con [kohya-ss/sd-scripts](https://github.com/kohya-ss/sd-scripts).\n",
    "Los pasos principales son:\n\n",
    "1. Instalar/usar un entorno gestionado por [uv](https://github.com/astral-sh/uv).\n",
    "2. Detectar el repositorio backend y exponer el m\u00f3dulo `sd_scripts` con las utilidades de `utils.kohya`.\n",
    "3. Instalar las dependencias necesarias (backend, kohya y extras de este fork).\n",
    "4. Configurar las rutas de trabajo del LoRA y definir los par\u00e1metros b\u00e1sicos del entrenamiento.\n",
    "5. Generar los ficheros `config.toml` y `dataset.toml` con `utils.process`.\n",
    "6. Construir el comando de entrenamiento con `build_training_command` y, opcionalmente, lanzarlo desde el cuaderno.\n\n",
    "Completa los valores marcados como ``<...>`` antes de ejecutar el entrenamiento real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "LIGHTNING_ROOT = Path(\"/teamspace/studios/this_studio\")\n",
    "UV_BIN = Path.home() / \".local\" / \"bin\" / \"uv\"\n",
    "\n",
    "if not UV_BIN.exists():\n",
    "    print(\"Instalando uv\u2026\")\n",
    "    subprocess.run(\n",
    "        [\"/bin/bash\", \"-lc\", \"curl -LsSf https://astral.sh/uv/install.sh | sh\"],\n",
    "        check=True,\n",
    "    )\n",
    "else:\n",
    "    print(\"uv ya est\u00e1 instalado\")\n",
    "\n",
    "os.environ[\"PATH\"] = f\"{UV_BIN.parent}:{os.environ['PATH']}\"\n",
    "os.environ.setdefault(\"UV_PROJECT_ENVIRONMENT\", str(LIGHTNING_ROOT / \".venv\"))\n",
    "print(\"Entorno de uv:\", os.environ[\"UV_PROJECT_ENVIRONMENT\"])\n",
    "\n",
    "project_root = Path.cwd().resolve()\n",
    "if not (project_root / \"utils\").exists():\n",
    "    candidate = project_root / \"LoRA_Easy_Training_scripts_Backend\"\n",
    "    if candidate.exists():\n",
    "        project_root = candidate.resolve()\n",
    "if not (project_root / \"utils\").exists():\n",
    "    raise FileNotFoundError(\"No se encontr\u00f3 la carpeta 'utils' junto al notebook.\")\n",
    "\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "print(\"Repositorio detectado en:\", project_root)\n",
    "\n",
    "from utils.kohya import ensure_on_path, get_repo_root\n",
    "\n",
    "ensure_on_path()\n",
    "kohya_root = get_repo_root()\n",
    "print(\"Repositorio kohya:\", kohya_root)\n",
    "\n",
    "runtime_store = project_root / \"runtime_store\"\n",
    "runtime_store.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Carpeta runtime_store lista en:\", runtime_store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import subprocess\n",
    "\n",
    "    commands: list[list[str]] = []\n",
    "\n",
    "    base_requirements = project_root / \"requirements.txt\"\n",
    "    if base_requirements.exists():\n",
    "        commands.append([\"uv\", \"pip\", \"install\", \"--upgrade\", \"-r\", str(base_requirements)])\n",
    "\n",
    "    for local_pkg in (\"custom_scheduler\", \"lycoris\"):\n",
    "        pkg_path = project_root / local_pkg\n",
    "        if pkg_path.exists():\n",
    "            commands.append([\"uv\", \"pip\", \"install\", \"--upgrade\", str(pkg_path)])\n",
    "\n",
    "    kohya_requirements = kohya_root / \"requirements.txt\"\n",
    "    if kohya_requirements.exists():\n",
    "        commands.append([\"uv\", \"pip\", \"install\", \"--upgrade\", \"-r\", str(kohya_requirements)])\n",
    "    else:\n",
    "        print(\"No se encontr\u00f3 requirements.txt dentro de sd_scripts; se omite la instalaci\u00f3n espec\u00edfica.\")\n",
    "\n",
    "    for command in commands:\n",
    "        print(\"Ejecutando:\", \" \".join(command))\n",
    "        subprocess.run(command, check=True)\n",
    "\n",
    "    accelerate_config = LIGHTNING_ROOT / \".cache\" / \"huggingface\" / \"accelerate\" / \"default_config.yaml\"\n",
    "    if not accelerate_config.exists():\n",
    "        accelerate_config.parent.mkdir(parents=True, exist_ok=True)\n",
    "        accelerate_config.write_text(\n",
    "            \"command_file: null\n",
    "\"\n",
    "            \"commands: null\n",
    "\"\n",
    "            \"compute_environment: LOCAL_MACHINE\n",
    "\"\n",
    "            \"deepspeed_config: {}\n",
    "\"\n",
    "            \"distributed_type: 'NO'\n",
    "\"\n",
    "            \"downcase_fp16: 'NO'\n",
    "\"\n",
    "            \"dynamo_backend: 'NO'\n",
    "\"\n",
    "            \"fsdp_config: {}\n",
    "\"\n",
    "            \"gpu_ids: '0'\n",
    "\"\n",
    "            \"machine_rank: 0\n",
    "\"\n",
    "            \"main_process_ip: null\n",
    "\"\n",
    "            \"main_process_port: null\n",
    "\"\n",
    "            \"main_training_function: main\n",
    "\"\n",
    "            \"megatron_lm_config: {}\n",
    "\"\n",
    "            \"mixed_precision: bf16\n",
    "\"\n",
    "            \"num_machines: 1\n",
    "\"\n",
    "            \"num_processes: 1\n",
    "\"\n",
    "            \"rdzv_backend: static\n",
    "\"\n",
    "            \"same_network: true\n",
    "\"\n",
    "            \"tpu_name: null\n",
    "\"\n",
    "            \"tpu_zone: null\n",
    "\"\n",
    "            \"use_cpu: false\"\n",
    "        )\n",
    "        print(\"Archivo de configuraci\u00f3n de accelerate creado en:\", accelerate_config)\n",
    "    else:\n",
    "        print(\"Configuraci\u00f3n de accelerate existente en:\", accelerate_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.process import process_args, process_dataset_args\n",
    "\n",
    "lora_name = \"mi_lora_kohya\"\n",
    "workspace_root = (LIGHTNING_ROOT / \"Loras\" / lora_name).resolve()\n",
    "dataset_workspace = workspace_root / \"dataset\"\n",
    "output_workspace = workspace_root / \"output\"\n",
    "dataset_workspace.mkdir(parents=True, exist_ok=True)\n",
    "output_workspace.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Directorio de trabajo del LoRA:\", workspace_root)\n",
    "print(\"Carpeta del dataset:\", dataset_workspace)\n",
    "print(\"Carpeta de salida:\", output_workspace)\n",
    "\n",
    "config_args = {\n",
    "    \"pretrained_model_name_or_path\": \"<RUTA_ABSOLUTA_DEL_MODELO_BASE>\",\n",
    "    \"vae\": \"<RUTA_OPCIONAL_DEL_VAE>\",\n",
    "    \"output_dir\": output_workspace.as_posix(),\n",
    "    \"logging_dir\": (output_workspace / \"logs\").as_posix(),\n",
    "    \"network_module\": \"networks.lora\",\n",
    "    \"network_dim\": 32,\n",
    "    \"network_alpha\": 32,\n",
    "    \"train_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"max_train_steps\": 1000,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"unet_lr\": 1e-4,\n",
    "    \"text_encoder_lr\": 5e-6,\n",
    "    \"optimizer_type\": \"AdamW8bit\",\n",
    "    \"save_every_n_steps\": 200,\n",
    "    \"mixed_precision\": \"bf16\",\n",
    "    \"cache_latents\": True,\n",
    "    \"clip_skip\": 2,\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "dataset_args = {\n",
    "    \"general\": {\n",
    "        \"resolution\": 1024,\n",
    "        \"shuffle_caption\": True,\n",
    "        \"caption_extension\": \".txt\",\n",
    "        \"keep_tokens\": 1,\n",
    "    },\n",
    "    \"subsets\": [\n",
    "        {\n",
    "            \"image_dir\": dataset_workspace.as_posix(),\n",
    "            \"caption_dropout_rate\": 0.0,\n",
    "            \"caption_dropout_every_n_epochs\": 0,\n",
    "            \"num_repeats\": 1,\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "config_lines, config_path = process_args(config_args)\n",
    "dataset_lines, dataset_path = process_dataset_args(dataset_args)\n",
    "\n",
    "print(\"config.toml generado en:\", config_path)\n",
    "print(\"dataset.toml generado en:\", dataset_path)\n",
    "print(\"Entradas de config.toml:\")\n",
    "for line in config_lines:\n",
    "    print(\"  \", line)\n",
    "print(\"Secciones de dataset.toml:\")\n",
    "for line in dataset_lines.get(\"general\", []):\n",
    "    print(\"  \", line)\n",
    "for index, subset in enumerate(dataset_lines.get(\"subsets\", []), start=1):\n",
    "    print(f\"  [[datasets.subsets]] #{index}\")\n",
    "    for value in subset:\n",
    "        print(\"    \", value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex\n",
    "\n",
    "from utils.kohya import (\n",
    "    build_training_command,\n",
    "    get_training_script,\n",
    "    inherit_environment,\n",
    "    normalise_extra_args,\n",
    ")\n",
    "\n",
    "train_mode = \"lora\"\n",
    "is_sdxl = True\n",
    "is_flux = False\n",
    "extra_cli_arguments = \"--min_snr_gamma=5.0\"\n",
    "use_accelerate = True\n",
    "\n",
    "script_path = get_training_script(train_mode, is_sdxl, is_flux)\n",
    "command = build_training_command(\n",
    "    sys.executable,\n",
    "    script_path,\n",
    "    config_path.resolve(),\n",
    "    dataset_path.resolve(),\n",
    "    normalise_extra_args(extra_cli_arguments),\n",
    "    use_accelerate,\n",
    ")\n",
    "\n",
    "print(\"Script seleccionado:\", script_path.name)\n",
    "print(\"Comando completo:\")\n",
    "print(shlex.join(command))\n",
    "\n",
    "run_training = False\n",
    "if run_training:\n",
    "    completed = subprocess.run(\n",
    "        command,\n",
    "        cwd=str(script_path.parent),\n",
    "        env=inherit_environment(),\n",
    "        check=True,\n",
    "    )\n",
    "    print(\"Proceso finalizado con c\u00f3digo:\", completed.returncode)\n",
    "else:\n",
    "    print(\"Define `run_training = True` para lanzar el entrenamiento una vez revisados los par\u00e1metros.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}