{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0baa838",
   "metadata": {},
   "source": [
    "# Lightning AI SDXL LoRA Trainer\n",
    "\n",
    "Este cuaderno prepara un entorno dentro de Lightning AI (ruta raíz ``/teamspace/studios/this_studio``)\n",
    "y ejecuta el entrenador de LoRA para Stable Diffusion XL incluido en este fork.\n",
    "\n",
    "Los pasos principales son:\n",
    "\n",
    "1. Crear/usar un entorno gestionado por [uv](https://github.com/astral-sh/uv).\n",
    "2. Introducir un nombre de LoRA; el cuaderno creará `/teamspace/studios/this_studio/Loras/<nombre>/` con las subcarpetas\n",
    "   `dataset/` y `output/`. Copia tus imágenes y `.txt` dentro de `dataset/`. Puedes definir *activation tags* globales y\n",
    "   habilitar el mezclado de tags desde la configuración.\n",
    "3. Instalar las dependencias necesarias.\n",
    "4. Definir la configuración de entrenamiento (epochs, repeats, tasas de aprendizaje, tags, modelo base y VAE a descargar automáticamente, etc.).\n",
    "5. Ejecutar el entrenamiento calculando automáticamente los *steps* mediante la fórmula requerida.\n",
    "6. Seleccionar optimizadores personalizados (AdamW8bit, Prodigy, DAdapt*, Lion, etc.) y schedulers (`cosine`, `rex`,\n",
    "   `cosine_with_restarts`, entre otros) incluidos en este fork.\n",
    "7. Activa o desactiva los valores recomendados de cada optimizador con `use_optimizer_recommended_args` si quieres aplicar los presets sugeridos (Adafactor, AdamW8bit, Prodigy y CAME) sin tocar manualmente `optimizer_kwargs`.\n",
    "8. Define el nombre final del archivo LoRA con `lora_name` o la bandera `--lora-name` para controlar el `.safetensors` generado.\n",
    "9. Decide si quieres descargar el modelo base en formato Diffusers o como `.safetensors` con `load_diffusers_format` y, para los presets que lo necesiten (como NoobAI), fuerza o desactiva `v_prediction` desde la configuración o la CLI.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c708c87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uv ya está instalado\n",
      "Entorno de uv: /teamspace/studios/this_studio/.venv\n",
      "Repositorio detectado en: /teamspace/studios/this_studio/LoRA_Easy_Training_scripts_Backend\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "LIGHTNING_ROOT = Path(\"/teamspace/studios/this_studio\")\n",
    "UV_BIN = Path.home() / \".local\" / \"bin\" / \"uv\"\n",
    "\n",
    "if not UV_BIN.exists():\n",
    "    print(\"Instalando uv…\")\n",
    "    subprocess.run(\n",
    "        [\"/bin/bash\", \"-lc\", \"curl -LsSf https://astral.sh/uv/install.sh | sh\"],\n",
    "        check=True,\n",
    "    )\n",
    "else:\n",
    "    print(\"uv ya está instalado\")\n",
    "\n",
    "os.environ[\"PATH\"] = f\"{UV_BIN.parent}:{os.environ['PATH']}\"\n",
    "os.environ.setdefault(\"UV_PROJECT_ENVIRONMENT\", str(LIGHTNING_ROOT / \".venv\"))\n",
    "print(\"Entorno de uv:\", os.environ[\"UV_PROJECT_ENVIRONMENT\"])\n",
    "\n",
    "repo_root = Path.cwd().resolve()\n",
    "if not (repo_root / \"lightning_ai\").exists():\n",
    "    candidate = repo_root / \"LoRA_Easy_Training_scripts_Backend\"\n",
    "    if candidate.exists():\n",
    "        repo_root = candidate.resolve()\n",
    "if not (repo_root / \"lightning_ai\").exists():\n",
    "    raise FileNotFoundError(\"No se encontró la carpeta 'lightning_ai' junto al notebook.\")\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "print(\"Repositorio detectado en:\", repo_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "250cecfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando dependencias con uv…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.11 environment at: /home/zeus/miniconda3/envs/cloudspace\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m74 packages\u001b[0m \u001b[2min 846ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m74 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['uv', 'pip', 'install', '--upgrade', 'numpy<2', 'bitsandbytes==0.45.2', 'prodigyopt', 'lion-pytorch==0.0.6', 'dadaptation', 'wheel', 'pytorch-optimizer==3.1.2', 'torch>=2.1', 'torchvision', 'accelerate>=0.23', 'diffusers[torch]==0.25', 'transformers==4.44.0', 'peft>=0.7', 'safetensors==0.4.4', 'huggingface-hub==0.24.5', 'toml==0.10.2', 'tensorboard', 'pytorch-lightning==1.9.0', 'opencv-python==4.8.1.78', 'xformers'], returncode=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "required_packages = [\n",
    "    \"numpy<2\",\n",
    "    \"bitsandbytes==0.45.2\",\n",
    "    \"prodigyopt\",\n",
    "    \"lion-pytorch==0.0.6\",\n",
    "    \"dadaptation\",\n",
    "    \"wheel\",\n",
    "    \"pytorch-optimizer==3.1.2\",\n",
    "    \"torch>=2.1\",\n",
    "    \"torchvision\",\n",
    "    \"accelerate>=0.23\",\n",
    "    \"diffusers[torch]==0.25\",\n",
    "    \"transformers==4.44.0\",\n",
    "    \"peft>=0.7\",\n",
    "    \"safetensors==0.4.4\",\n",
    "    \"huggingface-hub==0.24.5\",\n",
    "    \"toml==0.10.2\",\n",
    "    \"tensorboard\",\n",
    "    \"pytorch-lightning==1.9.0\",\n",
    "    \"opencv-python==4.8.1.78\",\n",
    "    \"xformers\",\n",
    "]\n",
    "print(\"Instalando dependencias con uv…\")\n",
    "subprocess.run([\"uv\", \"pip\", \"install\", \"--upgrade\", *required_packages], check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed0efe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directorio de trabajo del LoRA: /teamspace/studios/this_studio/Loras/praxysxenoblade\n",
      "Modelos base disponibles (Diffusers / Safetensors):\n",
      "  - Pony Diffusion V6 XL: diffusers=WhiteAiZ/Pony_diffusion_v6_diffusers_fp16 | safetensors=https://huggingface.co/WhiteAiZ/PonyXL/resolve/main/PonyDiffusionV6XL.safetensors\n",
      "  - Animagine XL V3: diffusers=cagliostrolab/animagine-xl-3.0 | safetensors=https://civitai.com/api/download/models/293564\n",
      "  - animagine_4.0_zero: diffusers=cagliostrolab/animagine-xl-4.0-zero | safetensors=https://huggingface.co/cagliostrolab/animagine-xl-4.0-zero/resolve/main/animagine-xl-4.0-zero.safetensors\n",
      "  - Illustrious_0.1: diffusers=OnomaAIResearch/Illustrious-xl-early-release-v0 | safetensors=https://huggingface.co/OnomaAIResearch/Illustrious-xl-early-release-v0/resolve/main/Illustrious-XL-v0.1.safetensors\n",
      "  - Illustrious_2.0: diffusers=WhiteAiZ/Illustrious_2.0 | safetensors=https://huggingface.co/WhiteAiZ/Illustrious_2.0/resolve/main/illustriousXL20_v20.safetensors\n",
      "  - NoobAI-XL0.75: diffusers=Laxhar/noobai-XL-0.75 | safetensors=https://huggingface.co/Laxhar/noobai-XL-0.75/resolve/main/NoobAI-XL-v0.75.safetensors\n",
      "  - NoobAI-XL0.5: diffusers=Laxhar/noobai-XL-0.5 | safetensors=https://huggingface.co/Laxhar/noobai-XL-0.5/resolve/main/NoobAI-XL-v0.5.safetensors\n",
      "  - Stable Diffusion XL 1.0 base: diffusers=stabilityai/stable-diffusion-xl-base-1.0 | safetensors=https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\n",
      "  - NoobAIXL0_75vpred: diffusers=Laxhar/noobai-XL-Vpred-0.75 | safetensors=https://huggingface.co/Laxhar/noobai-XL-Vpred-0.75/resolve/main/NoobAI-XL-Vpred-v0.75.safetensors\n",
      "  - RouWei_v080vpred: diffusers=John6666/rouwei-v080-vpred-sdxl | safetensors=https://huggingface.co/WhiteAiZ/RouWei/resolve/main/rouwei_v080Vpred.safetensors\n",
      "VAEs disponibles (Diffusers / Safetensors):\n",
      "  - Stability AI SDXL VAE: diffusers=stabilityai/sdxl-vae | safetensors=https://huggingface.co/stabilityai/sdxl-vae/resolve/main/sdxl_vae.safetensors\n",
      "  - Made by Ollin SDXL VAE FP16 Fix: diffusers=madebyollin/sdxl-vae-fp16-fix | safetensors=https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/sdxl_vae.safetensors\n",
      "  - Turbo VAE XL: diffusers=segmind/turbo-sdxl-vae | safetensors=https://huggingface.co/segmind/turbo-sdxl-vae/resolve/main/diffusion_pytorch_model.safetensors\n",
      "Configuración resuelta:\n",
      "  dataset_dir: /teamspace/studios/this_studio/Loras/praxysxenoblade/dataset\n",
      "  output_dir: /teamspace/studios/this_studio/Loras/praxysxenoblade/output\n",
      "  num_epochs: 15\n",
      "  batch_size: 4\n",
      "  gradient_accumulation: 1\n",
      "  num_repeats: 2\n",
      "  resolution: 1024\n",
      "  network_rank: 16\n",
      "  network_alpha: 32\n",
      "  unet_lr: 0.0001\n",
      "  text_encoder_lr: 5e-05\n",
      "  train_text_encoders: True\n",
      "  mixed_precision: fp16\n",
      "  seed: None\n",
      "  pretrained_model_name_or_path: stabilityai/stable-diffusion-xl-base-1.0\n",
      "  base_model: Illustrious_2.0\n",
      "  load_diffusers_format: True\n",
      "  v_prediction: None\n",
      "  vae_model: Stability AI SDXL VAE\n",
      "  vae_model_name_or_path: None\n",
      "  optimizer_type: came\n",
      "  weight_decay: 0.0\n",
      "  optimizer_beta1: 0.9\n",
      "  optimizer_beta2: 0.999\n",
      "  optimizer_eps: 1e-08\n",
      "  optimizer_momentum: 0.9\n",
      "  scheduler_type: rex\n",
      "  lr_warmup_steps: 100\n",
      "  scheduler_first_cycle_steps: None\n",
      "  scheduler_cycle_multiplier: 1.0\n",
      "  scheduler_gamma: 8.0\n",
      "  scheduler_min_lr: 1e-06\n",
      "  scheduler_d: 0.9\n",
      "  scheduler_power: 1.0\n",
      "  optimizer_kwargs: {}\n",
      "  scheduler_kwargs: {}\n",
      "  shuffle_tags: True\n",
      "  activation_tags: ('mi_lora',)\n",
      "  use_optimizer_recommended_args: True\n",
      "  lora_name: praxysxenoblade\n",
      "  cross_attention_backend: xformers\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from lightning_ai.sdxl_lora_trainer import (\n",
    "    BASE_MODEL_PRESETS,\n",
    "    VAE_PRESETS,\n",
    "    TrainingConfig,\n",
    ")\n",
    "\n",
    "lora_name = \"praxysxenoblade\"\n",
    "\n",
    "lora_workspace = (LIGHTNING_ROOT / \"Loras\" / lora_name).resolve()\n",
    "dataset_workspace = lora_workspace / \"dataset\"\n",
    "output_workspace = lora_workspace / \"output\"\n",
    "dataset_workspace.mkdir(parents=True, exist_ok=True)\n",
    "output_workspace.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "base_config = TrainingConfig(\n",
    "    dataset_dir=dataset_workspace,  # carpeta con imágenes y .txt emparejados\n",
    "    output_dir=output_workspace,\n",
    "    num_epochs=15,\n",
    "    batch_size=4,\n",
    "    gradient_accumulation=1,\n",
    "    num_repeats=2,\n",
    "    resolution=1024,\n",
    "    network_rank=16,\n",
    "    network_alpha=32,\n",
    "    base_model=\"Illustrious_2.0\",\n",
    "    load_diffusers_format=True,  # cambia a False para descargar checkpoints .safetensors\n",
    "    v_prediction=None,  # usa True/False para forzar o desactivar v-prediction manualmente\n",
    "    vae_model=\"Stability AI SDXL VAE\",\n",
    "    unet_lr=1e-4,\n",
    "    text_encoder_lr=5e-5,\n",
    "    optimizer_type=\"came\",\n",
    "    weight_decay=0.0,\n",
    "    optimizer_beta1=0.9,\n",
    "    optimizer_beta2=0.999,\n",
    "    optimizer_eps=1e-8,\n",
    "    optimizer_momentum=0.9,\n",
    "    scheduler_type=\"rex\",\n",
    "    lr_warmup_steps=100,\n",
    "    scheduler_first_cycle_steps=None,\n",
    "    scheduler_cycle_multiplier=1.0,\n",
    "    scheduler_gamma=8.0,\n",
    "    scheduler_min_lr=1e-6,\n",
    "    scheduler_d=0.9,\n",
    "    scheduler_power=1.0,\n",
    "    train_text_encoders=True,\n",
    "    mixed_precision=\"fp16\",\n",
    "    shuffle_tags=True,\n",
    "    activation_tags=(\"mi_lora\",),\n",
    "    use_optimizer_recommended_args=True,\n",
    "    cross_attention_backend=\"xformers\",\n",
    "    lora_name=lora_name,  # la extensión .safetensors se añade si falta\n",
    ")\n",
    "\n",
    "print(\"Directorio de trabajo del LoRA:\", lora_workspace)\n",
    "print(\"Modelos base disponibles (Diffusers / Safetensors):\")\n",
    "for name, preset in BASE_MODEL_PRESETS.items():\n",
    "    print(f\"  - {name}: diffusers={preset.diffusers_id} | safetensors={preset.single_file_url}\")\n",
    "\n",
    "print(\"VAEs disponibles (Diffusers / Safetensors):\")\n",
    "for name, preset in VAE_PRESETS.items():\n",
    "    print(f\"  - {name}: diffusers={preset.diffusers_id} | safetensors={preset.single_file_url}\")\n",
    "\n",
    "config = base_config.normalised_paths()\n",
    "print(\"Configuración resuelta:\")\n",
    "for key, value in config.__dict__.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0910a55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"num_images\": 24,\n",
      "  \"num_repeats\": 2,\n",
      "  \"num_epochs\": 15,\n",
      "  \"batch_size\": 4,\n",
      "  \"calculated_steps\": 180\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from lightning_ai.sdxl_lora_trainer import FolderCaptionDataset, calculate_total_steps\n",
    "\n",
    "preview_dataset = FolderCaptionDataset(\n",
    "    dataset_dir=config.dataset_dir,\n",
    "    resolution=config.resolution,\n",
    "    activation_tags=config.activation_tags,\n",
    "    shuffle_tags=config.shuffle_tags,\n",
    ")\n",
    "\n",
    "num_images = len(preview_dataset)\n",
    "steps = calculate_total_steps(\n",
    "    num_images=num_images,\n",
    "    num_repeats=config.num_repeats,\n",
    "    num_epochs=config.num_epochs,\n",
    "    batch_size=config.batch_size,\n",
    ")\n",
    "print(json.dumps(\n",
    "    {\n",
    "        \"num_images\": num_images,\n",
    "        \"num_repeats\": config.num_repeats,\n",
    "        \"num_epochs\": config.num_epochs,\n",
    "        \"batch_size\": config.batch_size,\n",
    "        \"calculated_steps\": steps,\n",
    "    },\n",
    "    indent=2,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f951bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento…\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e54cba7d8e247a09fb9e03c4fcf2243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "The config attributes {'latents_mean': None, 'latents_std': None, 'mid_block_add_attention': True, 'shift_factor': None, 'use_post_quant_conv': True, 'use_quant_conv': True} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "Could not find the bitsandbytes CUDA binary at PosixPath('/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (128) must match the size of tensor b (1024) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlightning_ai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdxl_lora_trainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIniciando entrenamiento…\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LoRA_Easy_Training_scripts_Backend/lightning_ai/sdxl_lora_trainer.py:1167\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m   1165\u001b[0m latents \u001b[38;5;241m=\u001b[39m latents \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.18215\u001b[39m\n\u001b[1;32m   1166\u001b[0m noise \u001b[38;5;241m=\u001b[39m noise\u001b[38;5;241m.\u001b[39mto(latents\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 1167\u001b[0m noisy_latents \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_noise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m prompt_embeds, pooled_prompt_embeds \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mencode_prompt(\n\u001b[1;32m   1170\u001b[0m     batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompts\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1171\u001b[0m     device\u001b[38;5;241m=\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m   1172\u001b[0m     num_images_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1173\u001b[0m     do_classifier_free_guidance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m )\n\u001b[1;32m   1176\u001b[0m add_time_ids \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39m_get_add_time_ids(\n\u001b[1;32m   1177\u001b[0m     original_size\u001b[38;5;241m=\u001b[39m(config\u001b[38;5;241m.\u001b[39mresolution, config\u001b[38;5;241m.\u001b[39mresolution),\n\u001b[1;32m   1178\u001b[0m     crops_coords_top_left\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m   1179\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(config\u001b[38;5;241m.\u001b[39mresolution, config\u001b[38;5;241m.\u001b[39mresolution),\n\u001b[1;32m   1180\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mprompt_embeds\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m   1181\u001b[0m )\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/diffusers/schedulers/scheduling_ddpm.py:519\u001b[0m, in \u001b[0;36mDDPMScheduler.add_noise\u001b[0;34m(self, original_samples, noise, timesteps)\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sqrt_one_minus_alpha_prod\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(original_samples\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    517\u001b[0m     sqrt_one_minus_alpha_prod \u001b[38;5;241m=\u001b[39m sqrt_one_minus_alpha_prod\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 519\u001b[0m noisy_samples \u001b[38;5;241m=\u001b[39m \u001b[43msqrt_alpha_prod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moriginal_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msqrt_one_minus_alpha_prod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m noisy_samples\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (128) must match the size of tensor b (1024) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "from lightning_ai.sdxl_lora_trainer import train\n",
    "\n",
    "print(\"Iniciando entrenamiento…\")\n",
    "train(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3403c-103e-44b2-87b4-31678d47fb1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
